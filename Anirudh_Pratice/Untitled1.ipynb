{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T08:19:54.720764Z",
     "start_time": "2020-05-09T08:18:10.000588Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 102s 9us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T08:19:55.072430Z",
     "start_time": "2020-05-09T08:19:54.732959Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T08:20:26.079886Z",
     "start_time": "2020-05-09T08:20:25.837923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9536f160d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAOSElEQVR4nO3dfYyU5bnH8d91sERCqwFZXmLJAZtN1JxYutkQIycNJ42NbEyQPzxCtMHEZKtCQmNNDuGYFPUfcnLaauKRhCqBo3UJpij8YSqK9YVEqwNyEETrC9hSCCwYKPiGLtf5Yx/MivvcM8zzzAt7fT/JZGaea+55rgz89pmZe2Zuc3cBGPn+qdUNAGgOwg4EQdiBIAg7EARhB4K4oJk7mzBhgk+bNq2ZuwRC2bdvn44cOWLD1QqF3cyuk/SgpFGSHnH3FanbT5s2TZVKpcguASR0d3fn1up+Gm9moyT9j6Q5kq6UtMDMrqz3/gA0VpHX7DMlve/uH7r7KUnrJM0tpy0AZSsS9ksl/W3I9f3Ztm8ws14zq5hZpb+/v8DuABRRJOzDvQnwrc/euvsqd+929+6Ojo4CuwNQRJGw75c0dcj170s6UKwdAI1SJOxvSOo0s+lmNlrSfEmbymkLQNnqnnpz96/MbLGkZzU49bba3XeX1hmAUhWaZ3f3ZyQ9U1IvABqIj8sCQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EERTl2wGhjp16lSy/uyzzybrL774Yt377uvrS9a7urqS9TvvvDNZ7+npOeeeGo0jOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EwTw7Cvnss8+S9XvvvTe3tm7duuTYjz76KFmfOHFisn799dfn1ubNm5ccu2HDhmT9scceS9bbcZ69UNjNbJ+kE5IGJH3l7t1lNAWgfGUc2f/N3Y+UcD8AGojX7EAQRcPukjab2TYz6x3uBmbWa2YVM6v09/cX3B2AehUN+yx375I0R9IiM/vx2Tdw91Xu3u3u3R0dHQV3B6BehcLu7gey88OSnpI0s4ymAJSv7rCb2Vgz+96Zy5J+KmlXWY0BKFeRd+MnSXrKzM7czxPu/sdSukLb2LhxY7J+zz33JOu7duX//R83blxy7F133ZWs33fffcn62LFjk/WURYsWJevV5unbUd1hd/cPJf2wxF4ANBBTb0AQhB0IgrADQRB2IAjCDgTBV1yD27lzZ7J+4403JuunT59O1h988MHc2u23354cO3r06GS9mtRXZCdPnpwce8UVVyTrW7duraunVuLIDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBMM8+wp04cSJZnzVrVrLu7sn69u3bk/WrrroqWU8ZGBhI1m+55ZZk/cknn8ytPf3008mxqZ+hlqTz8VeXOLIDQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBDMs49wK1asSNZPnjyZrPf2Druq19eKzKNXU+2noqst+ZxyySWX1D32fMWRHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCYJ59BPj0009za319fYXu+/777y80/vjx47m1m266KTl28+bNhfb9yiuv5NauvvrqQvd9Pqp6ZDez1WZ22Mx2Ddk23syeM7P3svP0QtsAWq6Wp/FrJF131ralkra4e6ekLdl1AG2satjd/WVJH5+1ea6ktdnltZJuKLkvACWr9w26Se5+UJKy84l5NzSzXjOrmFmlv7+/zt0BKKrh78a7+yp373b37vPxR/qAkaLesB8ysymSlJ0fLq8lAI1Qb9g3SVqYXV4oaWM57QBolKrz7GbWJ2m2pAlmtl/SryStkLTezG6T9FdJ6UW80VCpNdK/+OKLQvd99OjRZH3s2LHJ+qJFi3Jrzz//fHLshRdemKw//vjjyXpXV1duzcySY0eiqmF39wU5pZ+U3AuABuLjskAQhB0IgrADQRB2IAjCDgTBV1xHgNT02ieffFLovtevX5+sP/DAA8n6sWPHcmvjx49Pjn3ttdeS9c7OzmQd38SRHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCYJ59BBgYGMitjRuX/uHf1E89S9Ly5cvraelrc+fOza098cQTybHVvuKKc8ORHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCYJ59BHjnnXdya6k5+FqMGTMmWX/44YeT9fnz5+fWmEdvLo7sQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAE8+zngb179ybr1157bW7t1KlThfY9Z86cZD01jy4xl95Oqh7ZzWy1mR02s11Dti03s7+b2Y7s1NPYNgEUVcvT+DWSrhtm+2/dfUZ2eqbctgCUrWrY3f1lSR83oRcADVTkDbrFZrYze5qf+0NnZtZrZhUzq/T39xfYHYAi6g37Skk/kDRD0kFJv867obuvcvdud+/u6Oioc3cAiqor7O5+yN0H3P20pN9JmlluWwDKVlfYzWzKkKvzJO3Kuy2A9lB1nt3M+iTNljTBzPZL+pWk2WY2Q5JL2ifp5w3sccR76aWXkvXUPLokTZ48Obd29913J8euWbMmWd+wYUOy/tBDDyXr1faP5qkadndfMMzmRxvQC4AG4uOyQBCEHQiCsANBEHYgCMIOBMFXXJtg9+7dyXq1r4maWbK+efPm3Nrll1+eHLtt27Zk/c0330zWP//882Qd7YMjOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EwTx7jb788svc2ttvv50c29XVlaxfcEH6n2HLli3JerW59JQ77rgjWe/r60vW33333br3jebiyA4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQTDPXqOjR4/m1mbMmJEcO2bMmGS92lz11KlTk/WUkydPJutLlixJ1keNGpWsV5unR/vgyA4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQTDPnqk2H93T01P3fb/wwgvJerV5dHdP1l9//fXc2s0335wc+8EHHyTrs2fPTtavueaaZB3to+qR3cymmtmfzGyPme02syXZ9vFm9pyZvZedj2t8uwDqVcvT+K8k/dLdr5B0taRFZnalpKWStrh7p6Qt2XUAbapq2N39oLtvzy6fkLRH0qWS5kpam91sraQbGtUkgOLO6Q06M5sm6UeS/ixpkrsflAb/IEiamDOm18wqZlbp7+8v1i2AutUcdjP7rqQ/SPqFu/+j1nHuvsrdu929u6Ojo54eAZSgprCb2Xc0GPTfu/uGbPMhM5uS1adIOtyYFgGUoerUmw2uF/yopD3u/pshpU2SFkpakZ1vbEiHTXLgwIFkvdrSxSkzZ85M1o8dO5asL1u2LFlfuXLlOfd0xq233pqsP/LII3XfN9pLLfPssyT9TNJbZrYj27ZMgyFfb2a3SfqrpBsb0yKAMlQNu7tvlWQ55Z+U2w6ARuHjskAQhB0IgrADQRB2IAjCDgTBV1wzkyZNStanT5+eW9u7d29y7GWXXZasHz9+PFmvNg8/ceKwn1SWJC1dmv5+0uLFi5P1aj8ljfMHR3YgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIJ59szFF1+crL/66qu5td7e3uTYTZs21dXTGZ2dncl6pVLJrV100UWF9o2RgyM7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgTBPHuNUt9337jxvP7JfATBkR0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgqgadjObamZ/MrM9ZrbbzJZk25eb2d/NbEd26ml8uwDqVcuHar6S9Et3325m35O0zcyey2q/dff/blx7AMpSy/rsByUdzC6fMLM9ki5tdGMAynVOr9nNbJqkH0n6c7ZpsZntNLPVZjYuZ0yvmVXMrNLf31+oWQD1qznsZvZdSX+Q9At3/4eklZJ+IGmGBo/8vx5unLuvcvdud+/u6OgooWUA9agp7Gb2HQ0G/ffuvkGS3P2Quw+4+2lJv5M0s3FtAiiqlnfjTdKjkva4+2+GbJ8y5GbzJO0qvz0AZanl3fhZkn4m6S0z25FtWyZpgZnNkOSS9kn6eUM6BFCKWt6N3yrJhik9U347ABqFT9ABQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCMHdv3s7M+iV9NGTTBElHmtbAuWnX3tq1L4ne6lVmb//s7sP+/ltTw/6tnZtV3L27ZQ0ktGtv7dqXRG/1alZvPI0HgiDsQBCtDvuqFu8/pV17a9e+JHqrV1N6a+lrdgDN0+ojO4AmIexAEC0Ju5ldZ2bvmtn7Zra0FT3kMbN9ZvZWtgx1pcW9rDazw2a2a8i28Wb2nJm9l50Pu8Zei3pri2W8E8uMt/Sxa/Xy501/zW5moyT9RdK1kvZLekPSAnd/u6mN5DCzfZK63b3lH8Awsx9LOinpf939X7Jt/yXpY3dfkf2hHOfu/9EmvS2XdLLVy3hnqxVNGbrMuKQbJN2qFj52ib7+XU143FpxZJ8p6X13/9DdT0laJ2luC/poe+7+sqSPz9o8V9La7PJaDf5nabqc3tqCux909+3Z5ROSziwz3tLHLtFXU7Qi7JdK+tuQ6/vVXuu9u6TNZrbNzHpb3cwwJrn7QWnwP4+kiS3u52xVl/FuprOWGW+bx66e5c+LakXYh1tKqp3m/2a5e5ekOZIWZU9XUZualvFulmGWGW8L9S5/XlQrwr5f0tQh178v6UAL+hiWux/Izg9LekrttxT1oTMr6Gbnh1vcz9faaRnv4ZYZVxs8dq1c/rwVYX9DUqeZTTez0ZLmS9rUgj6+xczGZm+cyMzGSvqp2m8p6k2SFmaXF0ra2MJevqFdlvHOW2ZcLX7sWr78ubs3/SSpR4PvyH8g6T9b0UNOX5dJ+r/stLvVvUnq0+DTui81+IzoNkmXSNoi6b3sfHwb9faYpLck7dRgsKa0qLd/1eBLw52SdmSnnlY/dom+mvK48XFZIAg+QQcEQdiBIAg7EARhB4Ig7EAQhB0IgrADQfw/cJ9KWHd1ZkgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 7777 # You may select anything up to 60,000\n",
    "print(y_train[image_index]) # The label is 8\n",
    "plt.imshow(x_train[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T08:20:46.501549Z",
     "start_time": "2020-05-09T08:20:46.490413Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T08:21:23.705164Z",
     "start_time": "2020-05-09T08:21:21.946950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T12:05:14.522834Z",
     "start_time": "2020-05-09T12:05:14.412265Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10\n",
    "# Use same hidden layer size for both hidden layers. Not a necessity.\n",
    "hidden_layer_size = 1000\n",
    "    \n",
    "# define how the model will look like\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # the first layer (the input layer)\n",
    "    # each observation is 28x28x1 pixels, therefore it is a tensor of rank 3\n",
    "    # since we don't know CNNs yet, we don't know how to feed such input into our net, so we must flatten the images\n",
    "    # there is a convenient method 'Flatten' that simply takes our 28x28x1 tensor and orders it into a (None,) \n",
    "    # or (28x28x1,) = (784,) vector\n",
    "    # this allows us to actually create a feed forward neural network\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)), # input layer\n",
    "    \n",
    "    # tf.keras.layers.Dense is basically implementing: output = activation(dot(input, weight) + bias)\n",
    "    # it takes several arguments, but the most important ones for us are the hidden_layer_size and the activation function\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 1st hidden layer\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 1st hidden layer\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 2nd hidden layer\n",
    "    \n",
    "    # the final layer is no different, we just make sure to activate it with softmax\n",
    "    tf.keras.layers.Dense(output_size, activation='softmax') # output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T12:31:11.673731Z",
     "start_time": "2020-05-09T12:05:17.413827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/35\n",
      "60000/60000 [==============================] - 41s 690us/sample - loss: 0.2027 - accuracy: 0.9396\n",
      "Epoch 2/35\n",
      "60000/60000 [==============================] - 41s 685us/sample - loss: 0.0971 - accuracy: 0.9715\n",
      "Epoch 3/35\n",
      "60000/60000 [==============================] - 42s 696us/sample - loss: 0.0718 - accuracy: 0.9788\n",
      "Epoch 4/35\n",
      "60000/60000 [==============================] - 43s 720us/sample - loss: 0.0563 - accuracy: 0.9827\n",
      "Epoch 5/35\n",
      "60000/60000 [==============================] - 44s 731us/sample - loss: 0.0498 - accuracy: 0.9860\n",
      "Epoch 6/35\n",
      "60000/60000 [==============================] - 44s 736us/sample - loss: 0.0390 - accuracy: 0.9892\n",
      "Epoch 7/35\n",
      "60000/60000 [==============================] - 44s 735us/sample - loss: 0.0380 - accuracy: 0.9891\n",
      "Epoch 8/35\n",
      "60000/60000 [==============================] - 44s 732us/sample - loss: 0.0354 - accuracy: 0.9904\n",
      "Epoch 9/35\n",
      "60000/60000 [==============================] - 44s 737us/sample - loss: 0.0276 - accuracy: 0.9923\n",
      "Epoch 10/35\n",
      "60000/60000 [==============================] - 45s 749us/sample - loss: 0.0324 - accuracy: 0.9920\n",
      "Epoch 11/35\n",
      "60000/60000 [==============================] - 45s 748us/sample - loss: 0.0258 - accuracy: 0.9930\n",
      "Epoch 12/35\n",
      "60000/60000 [==============================] - 45s 758us/sample - loss: 0.0261 - accuracy: 0.9938\n",
      "Epoch 13/35\n",
      "60000/60000 [==============================] - 46s 758us/sample - loss: 0.0237 - accuracy: 0.9940\n",
      "Epoch 14/35\n",
      "60000/60000 [==============================] - 46s 767us/sample - loss: 0.0247 - accuracy: 0.9943\n",
      "Epoch 15/35\n",
      "60000/60000 [==============================] - 42s 708us/sample - loss: 0.0217 - accuracy: 0.9945\n",
      "Epoch 16/35\n",
      "60000/60000 [==============================] - 40s 669us/sample - loss: 0.0179 - accuracy: 0.9958\n",
      "Epoch 17/35\n",
      "60000/60000 [==============================] - 41s 678us/sample - loss: 0.0236 - accuracy: 0.9950\n",
      "Epoch 18/35\n",
      "60000/60000 [==============================] - 42s 699us/sample - loss: 0.0213 - accuracy: 0.9950\n",
      "Epoch 19/35\n",
      "60000/60000 [==============================] - 43s 718us/sample - loss: 0.0199 - accuracy: 0.9953\n",
      "Epoch 20/35\n",
      "60000/60000 [==============================] - 43s 724us/sample - loss: 0.0216 - accuracy: 0.9955\n",
      "Epoch 21/35\n",
      "60000/60000 [==============================] - 44s 740us/sample - loss: 0.0154 - accuracy: 0.9968\n",
      "Epoch 22/35\n",
      "60000/60000 [==============================] - 45s 744us/sample - loss: 0.0231 - accuracy: 0.9953\n",
      "Epoch 23/35\n",
      "60000/60000 [==============================] - 45s 757us/sample - loss: 0.0155 - accuracy: 0.9965\n",
      "Epoch 24/35\n",
      "60000/60000 [==============================] - 45s 756us/sample - loss: 0.0175 - accuracy: 0.9968\n",
      "Epoch 25/35\n",
      "60000/60000 [==============================] - 45s 756us/sample - loss: 0.0173 - accuracy: 0.9962\n",
      "Epoch 26/35\n",
      "60000/60000 [==============================] - 46s 766us/sample - loss: 0.0123 - accuracy: 0.9971\n",
      "Epoch 27/35\n",
      "60000/60000 [==============================] - 47s 776us/sample - loss: 0.0173 - accuracy: 0.9966\n",
      "Epoch 28/35\n",
      "60000/60000 [==============================] - 46s 772us/sample - loss: 0.0160 - accuracy: 0.9968\n",
      "Epoch 29/35\n",
      "60000/60000 [==============================] - 47s 782us/sample - loss: 0.0181 - accuracy: 0.9966\n",
      "Epoch 30/35\n",
      "60000/60000 [==============================] - 45s 754us/sample - loss: 0.0130 - accuracy: 0.9970\n",
      "Epoch 31/35\n",
      "60000/60000 [==============================] - 46s 759us/sample - loss: 0.0160 - accuracy: 0.9970\n",
      "Epoch 32/35\n",
      "60000/60000 [==============================] - 46s 762us/sample - loss: 0.0176 - accuracy: 0.9969\n",
      "Epoch 33/35\n",
      "60000/60000 [==============================] - 46s 772us/sample - loss: 0.0148 - accuracy: 0.9974\n",
      "Epoch 34/35\n",
      "60000/60000 [==============================] - 46s 774us/sample - loss: 0.0101 - accuracy: 0.9978\n",
      "Epoch 35/35\n",
      "60000/60000 [==============================] - 47s 786us/sample - loss: 0.0174 - accuracy: 0.9975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9465a8b190>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(x=x_train,y=y_train, epochs=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T09:16:21.185469Z",
     "start_time": "2020-05-09T09:16:20.977081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "0 6\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAOBklEQVR4nO3df6hc9ZnH8c/jtQFNguR6rzGml023qEQWNo2XUHCJWYohCpIUrDRgSVGM4K8GqhjaPyoaUFbboKDRm/XS7NK1RBMxirYNoRgLWnINWZO7111/XZPbXJKJEfPDP6LJs3/ck93bOPOdyZwzc6Z53i8YZuY8c+Y8GfK5Z2a+Z87X3F0Azn3nld0AgPYg7EAQhB0IgrADQRB2IIjz27mxnp4enzNnTjs3CYQyOjqqQ4cOWbVarrCb2RJJT0jqkvSv7v5o6vFz5szR0NBQnk0CSOjv769Za/ptvJl1SXpK0vWSrpK03Myuavb5ALRWns/sCyR94O4fufsJSb+VtLSYtgAULU/YZ0vaN+n+WLbsr5jZSjMbMrOhSqWSY3MA8sgT9mpfAnzt2Ft3H3D3fnfv7+3tzbE5AHnkCfuYpL5J978paX++dgC0Sp6w75B0uZl9y8ymSPqhpC3FtAWgaE0Pvbn7V2Z2t6Tfa2LobdDdhwvrDEChco2zu/trkl4rqBcALcThskAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgSRaxZXdIYXX3yxZu2mm25qYyfoZLnCbmajko5KOinpK3fvL6IpAMUrYs/+z+5+qIDnAdBCfGYHgsgbdpf0BzN7x8xWVnuAma00syEzG6pUKjk3B6BZecN+jbvPl3S9pLvMbOGZD3D3AXfvd/f+3t7enJsD0KxcYXf3/dn1QUkvSVpQRFMAitd02M1sqplNP31b0mJJe4pqDECx8nwbP1PSS2Z2+nn+w91/V0hXwZw4cSJZf+SRR5L1Dz/8sGaNcXac1nTY3f0jSf9YYC8AWoihNyAIwg4EQdiBIAg7EARhB4LgJ64d4PDhw8n6Qw89lKx//PHHRbaDcxR7diAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgnH2DnDvvfcm6wsWpM8JMmXKlCLbwTmKPTsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBME4exsMDw8n619++WWy/tZbbxXZTlulfqt//Pjx5Lp9fX3J+nvvvZesv/nmm8l6HldffXWyPn/+/JZtu1ns2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMbZ2+DVV19N1ru6utrUydcdPXo0WV+2bFmu5//0009r1r744ovkuldccUWyPjY2lqzv3r07Wc9j5syZyfrcuXOT9W3bthXZTkPq7tnNbNDMDprZnknLus1sq5m9n13PaG2bAPJq5G38ryUtOWPZaknb3P1ySduy+wA6WN2wu/t2SWce87hU0obs9gZJ+d7rAWi5Zr+gm+nu45KUXV9S64FmttLMhsxsqFKpNLk5AHm1/Nt4dx9w93537+/t7W315gDU0GzYD5jZLEnKrg8W1xKAVmg27Fskrchur5D0cjHtAGiVuuPsZva8pEWSesxsTNIvJD0qaaOZ3SZpr6QftLLJTldvrHrnzp3J+vr165P1vXv3JusXX3xxzdrUqVOT695xxx3JemqcXJJOnTqVrNf7LX/KqlWrkvWTJ0/mWj+PAwcOJOvXXXddy7bdrLphd/flNUrfK7gXAC3E4bJAEIQdCIKwA0EQdiAIwg4EwU9cC3Drrbcm65s3b871/CMjI8l66ie09Ybepk2blqy//vrrybq7J+ufffZZsp5y5ZVXJutHjhxJ1gcHB2vW6p2G+sSJE8n68uW1BqkmrFu3LlkvA3t2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCcfYGjY6O1qxt3bo1ue7ChQuT9ccffzxZf+yxx5L16dOnJ+spAwMDTa/biMsuu6xlz93d3Z2sv/322zVrq1enz5H65JNPJuuzZ89O1i+88MJkvQzs2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMbZG/TUU0/VrNU7lXS90zX39fUl6/XGfFHd8ePHa9Yivqbs2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMbZM88880yy/sQTT9Ss3Xjjjcl1b7755qZ6QtrTTz+drN933301a2vWrEmue//99yfrZpasd6K6e3YzGzSzg2a2Z9KyB83sL2a2K7vc0No2AeTVyNv4X0taUmX5Wnefl11eK7YtAEWrG3Z33y7pcBt6AdBCeb6gu9vM3s3e5s+o9SAzW2lmQ2Y2VKlUcmwOQB7Nhn2dpG9LmidpXNIvaz3Q3Qfcvd/d+3t7e5vcHIC8mgq7ux9w95PufkrSekkLim0LQNGaCruZzZp09/uS9tR6LIDOUHec3cyel7RIUo+ZjUn6haRFZjZPkksalZT+wfbfgDvvvDNZT42rdnV1Jdc97zyOXWrG2rVrk/VXXnklWU+dj3/JkmoDTP/v/PPPvUNQ6v6L3L3arPPPtaAXAC3ELgcIgrADQRB2IAjCDgRB2IEgzr3xhSa5e7KeGno7fDj904Fjx44l69OmTUvW/5bt3bu3Zi11em6p/tBbvVNwL19ebSBpwowZNY/wPmexZweCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIBhnz+Q5NfD27duT9dtvvz1ZHxwcTNYvuOCCs+6pKPv370/WN23alKynTud8yy23JNddt25dsr5o0aJkPeJYegp7diAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgnH2zNy5c5P18fHxmrXPP/88ue7GjRuT9Xq/pa83NXFqeuE9e/Kd0v/QoUPJ+sMPP5ysf/LJJzVrF110UXLdMo8vOBexZweCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIBhnzwwPDyfrqbHs6dOnJ9d94403kvUXXnghVz2PelMTr1mzJlm/9tprk/VLL730rHtCa9Tds5tZn5n90cxGzGzYzH6SLe82s61m9n52zZkCgA7WyNv4ryT91N3nSvqupLvM7CpJqyVtc/fLJW3L7gPoUHXD7u7j7r4zu31U0oik2ZKWStqQPWyDpGWtahJAfmf1BZ2ZzZH0HUl/ljTT3celiT8Iki6psc5KMxsys6FKpZKvWwBNazjsZjZN0iZJq9z9SKPrufuAu/e7e39vb28zPQIoQENhN7NvaCLov3H3zdniA2Y2K6vPknSwNS0CKELdoTebOMfyc5JG3P1Xk0pbJK2Q9Gh2/XJLOuwQDzzwQM1ad3d3ct177rknWV+8eHGyvm/fvmQ9j2effTZZX7p0acu2jfZqZJz9Gkk/krTbzHZly36miZBvNLPbJO2V9IPWtAigCHXD7u5/klRrBoXvFdsOgFbhcFkgCMIOBEHYgSAIOxAEYQeC4CeuDerp6Wl63XpTB+/YsaPp5wYaxZ4dCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCqBt2M+szsz+a2YiZDZvZT7LlD5rZX8xsV3a5ofXtAmhWI5NEfCXpp+6+08ymS3rHzLZmtbXu/njr2gNQlEbmZx+XNJ7dPmpmI5Jmt7oxAMU6q8/sZjZH0nck/TlbdLeZvWtmg2ZWdY4jM1tpZkNmNlSpVHI1C6B5DYfdzKZJ2iRplbsfkbRO0rclzdPEnv+X1dZz9wF373f3/t7e3gJaBtCMhsJuZt/QRNB/4+6bJcndD7j7SXc/JWm9pAWtaxNAXo18G2+SnpM04u6/mrR81qSHfV/SnuLbA1CURr6Nv0bSjyTtNrNd2bKfSVpuZvMkuaRRSXe0pEMAhWjk2/g/SbIqpdeKbwdAq3AEHRAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAhz9/ZtzKwi6ZNJi3okHWpbA2enU3vr1L4kemtWkb39nbtXPf9bW8P+tY2bDbl7f2kNJHRqb53al0RvzWpXb7yNB4Ig7EAQZYd9oOTtp3Rqb53al0RvzWpLb6V+ZgfQPmXv2QG0CWEHgigl7Ga2xMz+28w+MLPVZfRQi5mNmtnubBrqoZJ7GTSzg2a2Z9KybjPbambvZ9dV59grqbeOmMY7Mc14qa9d2dOft/0zu5l1SfofSddJGpO0Q9Jyd/+vtjZSg5mNSup399IPwDCzhZKOSfo3d/+HbNm/SDrs7o9mfyhnuPsDHdLbg5KOlT2NdzZb0azJ04xLWibpxyrxtUv0dbPa8LqVsWdfIOkDd//I3U9I+q2kpSX00fHcfbukw2csXippQ3Z7gyb+s7Rdjd46gruPu/vO7PZRSaenGS/1tUv01RZlhH22pH2T7o+ps+Z7d0l/MLN3zGxl2c1UMdPdx6WJ/zySLim5nzPVnca7nc6YZrxjXrtmpj/Pq4ywV5tKqpPG/65x9/mSrpd0V/Z2FY1paBrvdqkyzXhHaHb687zKCPuYpL5J978paX8JfVTl7vuz64OSXlLnTUV94PQMutn1wZL7+T+dNI13tWnG1QGvXZnTn5cR9h2SLjezb5nZFEk/lLSlhD6+xsymZl+cyMymSlqszpuKeoukFdntFZJeLrGXv9Ip03jXmmZcJb92pU9/7u5tv0i6QRPfyH8o6edl9FCjr7+X9J/ZZbjs3iQ9r4m3dV9q4h3RbZIulrRN0vvZdXcH9fbvknZLelcTwZpVUm//pImPhu9K2pVdbij7tUv01ZbXjcNlgSA4gg4IgrADQRB2IAjCDgRB2IEgCDsQBGEHgvhf0Kk60XtvHM4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 445\n",
    "print(x_test[image_index].shape)\n",
    "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
    "pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
    "print(pred.round(2))\n",
    "print(pred.argmax(),y_test[image_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T12:39:28.406219Z",
     "start_time": "2020-05-09T12:39:28.218187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "file='rsz_6.jpg'\n",
    "image = cv.imread(file, cv.IMREAD_GRAYSCALE)\n",
    "plt.imshow(image,cmap='Greys')\n",
    "pred = model.predict(image.reshape(1, 28, 28, 1))\n",
    "print(pred.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T09:54:53.868615Z",
     "start_time": "2020-05-09T09:54:53.818342Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected flatten_input to have 4 dimensions, but got array with shape (28, 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-d36fb0ce3b8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    427\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[0;32m--> 646\u001b[0;31m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[1;32m    647\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2383\u001b[0;31m         batch_size=batch_size)\n\u001b[0m\u001b[1;32m   2384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[0;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2410\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2412\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    571\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    574\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected flatten_input to have 4 dimensions, but got array with shape (28, 28)"
     ]
    }
   ],
   "source": [
    "\n",
    "pred=model.predict(image)\n",
    "print(pred.round(2),pred.argmax())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
